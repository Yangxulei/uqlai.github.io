<!DOCTYPE html>
<html>
  <head><meta name="generator" content="Hexo 3.8.0">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="UqRai&#39;s blog">
  <meta name="keyword" content="Python, Anguler.js">
  
    <link rel="shortcut icon" href="/css/images/logo.png">
  
  <title>
    
      list2-Running HelloWorld on Hadoop | Uqlai`blog
    
  </title>
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdn.bootcss.com/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">
<link rel="stylesheet" href="/css/plugins/gitment.css">
  <script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdn.bootcss.com/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>
  <script src="/js/qrious.js"></script>
<script src="/js/gitment.js"></script>
</head>
<div class="wechat-share">
  <img src="/css/images/logo.png">
</div>

  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>Uqlai`blog</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">Tags</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/project/" class="item-link">Projects</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/about/" class="item-link">About</a>
          
        </li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">Tags</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/project/" class="menu-link">Projects</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/about/" class="menu-link">About</a>
            
          </li>
        
      </ul>
    </div>
  </div>
</header>

    <div id="article-banner">
  <h2>list2-Running HelloWorld on Hadoop</h2>
  <p class="post-date">2017-07-11</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
    <section class="markdown-content"><p>上次笔记讲了关于大数据的基本内容和文章末尾给了配置Cloudera的教程，这次了解Hadoop文件系统或HDFS的基本文件操作命令。我们先从下载<a href="https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt" target="_blank" rel="noopener">text文件</a>开始。我们将使用这个text文件来复制HDFS中的本地文件系统，并使用它来运行word count<br><a id="more"></a></p>
<p>#1、 Copy your data into the Hadoop Distributed File System</p>
<p>下载文本文件后，我们将在Cloudera打开一个终端shell，并将文本文件从本地文件系统复制到HDFS。<br><img src="http://upload-images.jianshu.io/upload_images/744392-b634a4ed9c6e11c5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>接下来，我们将复制HDFS中的文件，还可以看到如何将文件从HDFS复制到本地文件系统。最后，我们将看看如何在HDFS中删除文件。</p>
<h4 id="一、复制"><a href="#一、复制" class="headerlink" title="一、复制"></a>一、复制</h4><p>让我们将word.txt从本地文件系统复制到HDFS文件系统:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs- copyFromLocal words.txt。</span><br></pre></td></tr></table></figure>
<p>当我运行它，它会将其从本地目录和本地文件系统复制到HDFS。</p>
<p>接下来，我们可以将此文件复制到HDFS中的另一个文件。我们可以通过运行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp words.txt words2.txt</span><br></pre></td></tr></table></figure></p>
<h4 id="二、查看"><a href="#二、查看" class="headerlink" title="二、查看"></a>二、查看</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls</span><br><span class="line">``` </span><br><span class="line">来查看存在的文件,可以在下图中看到第一个word.txt是HDFS中已经存在的文件。第二个word2.txt是我们运行此命令时要创建的新文件。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">![image.png](http://upload-images.jianshu.io/upload_images/744392-fb2b0ff94cfc63f9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">我们来将word2.txt从HDFS复制到本地文件系统。我们可以通过运行</span><br></pre></td></tr></table></figure>
<p>hadoop fs -copyToLocal word2.txt来执行此操作。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">运行此命令后，我可以调用ls来查看本地文件系统的内容。所以现在我们有刚刚从HDFS复制的新文件word2.txt。</span><br><span class="line">#### 三、删除HDFS文件</span><br><span class="line">我们可以通过运行</span><br></pre></td></tr></table></figure></p>
<p>hadoop fs -rm words2.txt<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">![image.png](http://upload-images.jianshu.io/upload_images/744392-109d0a915460b4e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)</span><br><span class="line"></span><br><span class="line">来删除words2.txt,你可以看到它打印出它删除了该文件。我们也可以运行hadoop fs -l来验证文件是否被删除。</span><br><span class="line"></span><br><span class="line"># 2、Run the WordCount program Instructions</span><br><span class="line"></span><br><span class="line">这个例子使用Hadoop来运行WordCount，这是入门几乎都会做的“hello world”吧。</span><br><span class="line"></span><br><span class="line">首先我们将打开一个终端shell并探索Hadoop提供的MapReduce程序，接下来验证HDFS中存在的输入文件。然后，运行WordCount并浏览WordCount输出目录，我们将WordCount的结果从HDFS复制到本地文件系统并查看，这就是这个例子的流程了。code起来~~</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">接下来，我们将看看生成的Hadoop程序。我们可以运行</span><br></pre></td></tr></table></figure></p>
<p>$Hadoop jar usr/jar/Hadoop-examples.jar <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">这个命令说明我们将使用jar命令从jar文件中在Hadoop中运行一个程序。而我们正在运行的jar文件位于/usr/jars/hadoop-examples.jar中。许多使用Java编写的程序通过jar文件进行分发。如果我们运行这个命令，我们将看到Hadoop附带的不同程序的列表。所以例如wordcount。计算文本文件中的单词。Wordmean，计算单词的平均长度。和其他程序，如排序和计算pi的长度。</span><br><span class="line"></span><br><span class="line">![image.png](http://upload-images.jianshu.io/upload_images/744392-e101358d28701d22.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)</span><br></pre></td></tr></table></figure></p>
<p>hadoop jar /usr/jars/hadoop-examples.jar wordcount<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">是说说，我们要运行一个jar，这是包含程序的jar的名字。而我们要运行的程序是wordcount。当我们运行它，我们看到它print命令行用法如何运行字数。这表示wordcount需要一个或多个输入文件和输出名称。现在，输入和输出均位于HDFS中。所以我们在HDFS中有刚刚列出的输入文件word.txt。我们可以运行wordcount。</span><br></pre></td></tr></table></figure></p>
<p> hadoop jar / usr / jars / hadoop-examples.jar wordcount words.txt<code>`</code></p>
<p>这就是说，我们将使用word.txt作为输入运行WordCount程序，并将输出放在一个名为out的目录中。run起来随着字数运行，print到屏幕。它将print，map的百分比并缩小完成。而当两者达到100％时，就完成了这项工作。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/744392-8a6da7faea9e6fe8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>我们通过运行<code>Hadoop fs -ls out</code>来查看输出结果的目录。 [BLANK AUDIO]我们可以看到目录中有两个文件。第一个是_SUCCESS，这意味着WordCount作业成功完成。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/744392-dd066963fa12f13a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>另一个文件-r-00000是包含WordCount命令输出的文本文件，现在我们可以通过运行<code>hadoop fs -copytolocal out / part-r-00000 loacl.txt</code>从HDFS将这个文本文件复制到本地文件系统，然后查看它。</p>
<p>我们在此文件中看到WordCount的结果。每行是一个特定的单词，第二列是在输入文件中找到该特定单词的单词数。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/744392-9819e482394066ce.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p><a href="https://www.coursera.org/learn/big-data-introduction/supplement/HIcQh/how-do-i-figure-out-how-to-run-hadoop-mapreduce-programs" target="_blank" rel="noopener"></a></p>
</section>
    <!-- Tags START -->
    
      <div class="tags">
        <span>Tags:</span>
        
  <a href="/tags#WordCount">
    <span class="tag-code">WordCount</span>
  </a>

      </div>
    
    <!-- Tags END -->
    <!-- 打赏 START -->
    
      <div class="money-like">
        <div class="reward-btn">
          赏
          <span class="money-code">
            <span class="alipay-code">
              <div class="code-image"></div>
              <b>使用支付宝打赏</b>
            </span>
            <span class="wechat-code">
              <div class="code-image"></div>
              <b>使用微信打赏</b>
            </span>
          </span>
        </div>
        <p class="notice">若你觉得我的文章对你有帮助，欢迎点击上方按钮对我打赏</p>
      </div>
    
    <!-- 打赏 END -->
    <!-- 二维码 START -->
    
      <div class="qrcode">
        <canvas id="share-qrcode"></canvas>
        <p class="notice">扫描二维码，分享此文章</p>
      </div>
    
    <!-- 二维码 END -->
    
      <!-- Gitment START -->
      <div id="comments"></div>
      <!-- Gitment END -->
    
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
  
    <aside class="catalog-container">
  <div class="toc-main">
    <strong class="toc-title">Catalog</strong>
    
      <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#一、复制"><span class="toc-nav-text">一、复制</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#二、查看"><span class="toc-nav-text">二、查看</span></a></li></ol>
    
  </div>
</aside>
  
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = 'http://uqlai.cn/2017/07/11/list2-Running-HelloWorld-on-Hadoop/';
    var banner = 'undefined'
    if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
      $('#article-banner').css({
        'background-image': 'url(' + banner + ')'
      })
    } else {
      $('#article-banner').geopattern(url)
    }
    $('.header').removeClass('fixed-header')

     // error image
    $(".markdown-content img").on('error', function() {
      $(this).attr('src', 'http://file.muyutech.com/error-img.png')
      $(this).css({
        'cursor': 'default'
      })
    })

    // zoom image
    $(".markdown-content img").on('click', function() {
      var src = $(this).attr('src')
      if (src !== 'http://file.muyutech.com/error-img.png') {
        var imageW = $(this).width()
        var imageH = $(this).height()
        
        var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
        zoom = zoom < 1 ? 1 : zoom
        zoom = zoom > 2 ? 2 : zoom
        var transY = (($(window).height() - imageH) / 2).toFixed(2)

        $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="'+ src +'" /></div></div>')
        $('.image-view-wrap').addClass('wrap-active')
        $('.image-view-wrap img').css({
          'width': `${imageW}`,
          'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
        })
        $('html').css('overflow', 'hidden')

        $('.image-view-wrap').on('click', function() {
          $(this).remove()
          $('html').attr('style', '')
        })
      }
    })

    // qrcode
    var qr = new QRious({
      element: document.getElementById('share-qrcode'),
      value: document.location.href
    });

    // gitment
    var gitmentConfig = "Yangxulei";
    if (gitmentConfig !== 'undefined') {
      var gitment = new Gitment({
        id: "list2-Running HelloWorld on Hadoop",
        owner: "Yangxulei",
        repo: "uqlai.github.io",
        oauth: {
          client_id: "21b7e54951fb0d13b30a",
          client_secret: "17474d9be1b0de2212e9992efb1a43b70efb2f5c"
        },
        theme: {
          render(state, instance) {
            const container = document.createElement('div')
            container.lang = "en-US"
            container.className = 'gitment-container gitment-root-container'
            container.appendChild(instance.renderHeader(state, instance))
            container.appendChild(instance.renderEditor(state, instance))
            container.appendChild(instance.renderComments(state, instance))
            container.appendChild(instance.renderFooter(state, instance))
            return container;
          }
        }
      })
      gitment.render(document.getElementById('comments'))
    }
  })();
</script>

    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
  <p class="copyright">
    &copy; 2018 | Proudly powered by <a href="https://hexo.io" target="_blank">Hexo</a>
    <br>
    Theme by <a href="https://github.com/yanm1ng">yanm1ng</a>
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->

<script src="/js/script.js"></script>
  </body>
</html>